{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/forecasting-beer-remote/auto-ml-forecasting-beer-remote.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "# Automated Machine Learning\n",
        "**Beer Production Forecasting**\n",
        "\n",
        "## Contents\n",
        "1. [Introduction](#Introduction)\n",
        "1. [Setup](#Setup)\n",
        "1. [Data](#Data)\n",
        "1. [Train](#Train)\n",
        "1. [Evaluate](#Evaluate)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "## Introduction\n",
        "This notebook demonstrates demand forecasting for Beer Production Dataset using AutoML.\n",
        "\n",
        "AutoML highlights here include using Deep Learning forecasts, Arima, Prophet,  Remote Execution and Remote Inferencing, and working with the `forecast` function. Please also look at the additional forecasting notebooks, which document lagging, rolling windows, forecast quantiles, other ways to use the forecast function, and forecaster deployment.\n",
        "\n",
        "Make sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n",
        "\n",
        "An Enterprise workspace is required for this notebook. To learn more about creating an Enterprise workspace or upgrading to an Enterprise workspace from the Azure portal, please visit our [Workspace page.](https://docs.microsoft.com/azure/machine-learning/service/concept-workspace#upgrade)\n",
        "\n",
        "Notebook synopsis:\n",
        "1. Creating an Experiment in an existing Workspace\n",
        "2. Configuration and remote run of AutoML for a time-series model exploring Regression learners, Arima, Prophet and DNNs\n",
        "4. Evaluating the fitted model using a rolling test "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "\n",
        "# Squash warning messages for cleaner output in the notebook\n",
        "warnings.showwarning = lambda *args, **kwargs: None\n",
        "\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from azureml.train.estimator import Estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkhsQzBSMTJza3hOWjFXUXdtak9GXzZ0X3RERSIsImtpZCI6IkhsQzBSMTJza3hOWjFXUXdtak9GXzZ0X3RERSJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC9lMjE4ZGRjZC1jYTYyLTQzNzgtYmJlMS0xMDliZGQwNGU4YTMvIiwiaWF0IjoxNTgzNDU4MTA0LCJuYmYiOjE1ODM0NTgxMDQsImV4cCI6MTU4MzQ2MjAwNCwiYWlvIjoiNDJOZ1lOaHkwYXlxdjNSS3hrN2VSZFhmYlhkc0FBQT0iLCJhcHBpZCI6IjIwYWQ0NWFhLTQ3NGQtNGFmYy04MzNiLTllNjI5MjEzMmQzOSIsImFwcGlkYWNyIjoiMSIsImlkcCI6Imh0dHBzOi8vc3RzLndpbmRvd3MubmV0L2UyMThkZGNkLWNhNjItNDM3OC1iYmUxLTEwOWJkZDA0ZThhMy8iLCJvaWQiOiJmZmVlMjRjYy0xNDY5LTQ1NWQtOTFkOC04YzhmZWI5MjJlMjIiLCJzdWIiOiJmZmVlMjRjYy0xNDY5LTQ1NWQtOTFkOC04YzhmZWI5MjJlMjIiLCJ0aWQiOiJlMjE4ZGRjZC1jYTYyLTQzNzgtYmJlMS0xMDliZGQwNGU4YTMiLCJ1dGkiOiJoeFh4OUQ3bHdFT1g4eHA5Tm1JQUFBIiwidmVyIjoiMS4wIn0.imFfnPT4AsPClMAZ9OcpoLNB4n7c6gMFDwJyJjYSHVzygRBnL5xd-11u26a8CfFEeXOS3ucWiiggPgm-nPnQHNoDMI7_N78rPZhJXXMwAEX1jn7EQWvY_sj5UXdIqVc6DkGpTzBZfZLzqtYLpyqXNojnUMgYVKEqlK7aDXTfJtVO4Y7CAyuTI7eZVMAhEiTMNvH7lOq9_ThJSHAIBX7Lm3tyGeeDihfZ5eDvjXCNw0IcwlI03_Y9qYEra8DMsu_5TnMouu_Fb8v_8aeNGhcNO1MqW_7fZ5zpkoaYWvtKFPwykmv-Fjn7WXYMYi-DGtnTfAp5jaEUAa7xhIvJOGqXUg'}\nFound workspace testground at location eastus2\n"
        }
      ],
      "source": [
        "# set up workspace\n",
        "import sys\n",
        "sys.path.append(r'C:\\Users\\jp\\Documents\\GitHub\\vault-private')\n",
        "import credentials\n",
        "\n",
        "ws = credentials.authenticate_AZR('gmail', 'testground') # auth & ws setup in one swing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.85</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>be8e48ab-94b2-4145-a6de-2104dc657912</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>testground</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>autoML</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>eastus2</td>\n    </tr>\n    <tr>\n      <th>Run History Name</th>\n      <td>beer-remote-cpu</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                      \nSDK version       1.0.85                              \nSubscription ID   be8e48ab-94b2-4145-a6de-2104dc657912\nWorkspace         testground                          \nResource Group    autoML                              \nLocation          eastus2                             \nRun History Name  beer-remote-cpu                     "
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for the run history container in the workspace\n",
        "experiment_name = 'beer-remote-cpu'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "output = {}\n",
        "output['SDK version'] = azureml.core.VERSION\n",
        "output['Subscription ID'] = ws.subscription_id\n",
        "output['Workspace'] = ws.name\n",
        "output['Resource Group'] = ws.resource_group\n",
        "output['Location'] = ws.location\n",
        "output['Run History Name'] = experiment_name\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "outputDf = pd.DataFrame(data = output, index = [''])\n",
        "outputDf.T"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "### Using AmlCompute\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you use `AmlCompute` as your training compute resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-de697abbed12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     default='cpu')\n\u001b[0;32m      7\u001b[0m \u001b[0mcompute_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'gpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'gpu-cluster'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'cpu-cluster'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'local'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'gpu-local'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcompute_target_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mcompute_target\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompute_target_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: None"
          ]
        }
      ],
      "source": [
        "import pyautogui\n",
        "cts = ws.compute_targets\n",
        "answer = pyautogui.prompt(\n",
        "    text='Enter compute target (gpu, cpu, or local)',\n",
        "    title='Compute target',\n",
        "    default='cpu')\n",
        "compute_dict = {'gpu':'gpu-cluster', 'cpu':'cpu-cluster', 'local':'gpu-local'}\n",
        "compute_target_name = compute_dict[answer]\n",
        "compute_target =cts[compute_target_name]\n",
        "print(compute_target.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "## Data\n",
        "Read Beer demand data from file, and preview data."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "Let's set up what we know about the dataset. \n",
        "\n",
        "**Target column** is what we want to forecast.\n",
        "\n",
        "**Time column** is the time axis along which to predict.\n",
        "\n",
        "**Grain** is another word for an individual time series in your dataset. Grains are identified by values of the columns listed `grain_column_names`, for example \"store\" and \"item\" if your data has multiple time series of sales, one series for each combination of store and item sold.\n",
        "\n",
        "This dataset has only one time series. Please see the [orange juice notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/forecasting-orange-juice-sales) for an example of a multi-time series dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import Grouper\n",
        "from matplotlib import pyplot\n",
        "from pandas import concat\n",
        "from matplotlib import pyplot\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "plt.tight_layout()\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('Beer Production By Year')\n",
        "df = pd.read_csv(\"Beer_no_valid_split_train.csv\", parse_dates=True, index_col= 'DATE').drop(columns='grain')\n",
        "test_df = pd.read_csv(\"Beer_no_valid_split_test.csv\", parse_dates=True, index_col= 'DATE').drop(columns='grain')\n",
        "pyplot.plot(df)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title('Beer Production By Month')\n",
        "groups = df.groupby(df.index.month)\n",
        "months = concat([DataFrame(x[1].values) for x in groups], axis=1)\n",
        "months = DataFrame(months)\n",
        "months.columns = range(1,13)\n",
        "months.boxplot()\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_column_name = 'BeerProduction'\n",
        "time_column_name = 'DATE'\n",
        "grain_column_names = []\n",
        "freq = 'M' #Monthly data"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Split Training data into Train and Validation set and Upload to Datastores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper import split_fraction_by_grain\n",
        "from helper import split_full_for_forecasting\n",
        "\n",
        "train, valid = split_full_for_forecasting(df, time_column_name)\n",
        "train.to_csv(\"train.csv\")\n",
        "valid.to_csv(\"valid.csv\")\n",
        "test_df.to_csv(\"test.csv\")\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload_files(files = ['./train.csv'], target_path = 'beer-dataset/tabular/', overwrite = True,show_progress = True)\n",
        "datastore.upload_files(files = ['./valid.csv'], target_path = 'beer-dataset/tabular/', overwrite = True,show_progress = True)\n",
        "datastore.upload_files(files = ['./test.csv'], target_path = 'beer-dataset/tabular/', overwrite = True,show_progress = True)\n",
        "\n",
        "from azureml.core import Dataset\n",
        "train_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'beer-dataset/tabular/train.csv')])\n",
        "valid_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'beer-dataset/tabular/valid.csv')])\n",
        "test_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'beer-dataset/tabular/test.csv')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset.to_pandas_dataframe().info()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "### Setting forecaster maximum horizon \n",
        "\n",
        "The forecast horizon is the number of periods into the future that the model should predict. Here, we set the horizon to 12 periods (i.e. 12 months). Notice that this is much shorter than the number of months in the test set; we will need to use a rolling test to evaluate the performance on the whole test set. For more discussion of forecast horizons and guiding principles for setting them, please see the [energy demand notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/forecasting-energy-demand).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_horizon = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "## Train\n",
        "\n",
        "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
        "\n",
        "|Property|Description|\n",
        "|-|-|\n",
        "|**task**|forecasting|\n",
        "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
        "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
        "|**training_data**|Input dataset, containing both features and label column.|\n",
        "|**label_column_name**|The name of the label column.|\n",
        "|**enable_dnn**|Enable Forecasting DNNs|\n",
        "\n",
        "This notebook uses the blacklist_models parameter to exclude some models that take a longer time to train on this dataset. You can choose to remove models from the blacklist_models list but you may need to increase the iteration_timeout_minutes parameter value to get results.\n",
        "\n",
        "This step requires an Enterprise workspace to gain access to this feature. To learn more about creating an Enterprise workspace or upgrading to an Enterprise workspace from the Azure portal, please visit our [Workspace page.](https://docs.microsoft.com/azure/machine-learning/service/concept-workspace#upgrade)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "automl_settings = {\n",
        "    'time_column_name': time_column_name,\n",
        "    'max_horizon': max_horizon,\n",
        "    'enable_dnn' : True,\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(task='forecasting',                             \n",
        "                             primary_metric='normalized_root_mean_squared_error',\n",
        "                             experiment_timeout_hours = 1,\n",
        "                             training_data=train_dataset,\n",
        "                             label_column_name=target_column_name,\n",
        "                             validation_data=valid_dataset, \n",
        "                             verbosity=logging.INFO,\n",
        "                             compute_target=compute_target,\n",
        "                             max_concurrent_iterations=4,\n",
        "                             max_cores_per_iteration=-1,\n",
        "                            **automl_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "We will now run the experiment, starting with 10 iterations of model search. The experiment can be continued for more iterations if more accurate results are required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remote_run = experiment.submit(automl_config, show_output= True)\n",
        "remote_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "# If you need to retrieve a run that already started, use the following code\n",
        "# from azureml.train.automl.run import AutoMLRun\n",
        "# remote_run = AutoMLRun(experiment = experiment, run_id = '<replace with your run id>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remote_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "Displaying the run objects gives you links to the visual tools in the Azure Portal. Go try them!"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "### Retrieve the Best Model for Each Algorithm\n",
        "Below we select the best pipeline from our iterations. The get_output method on automl_classifier returns the best run and the fitted model for the last fit invocation. There are overloads on get_output that allow you to retrieve the best run and fitted model for any logged metric or a particular iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper import get_result_df\n",
        "summary_df = get_result_df(remote_run)\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.run import Run\n",
        "from azureml.widgets import RunDetails\n",
        "forecast_model = 'TCNForecaster'\n",
        "if not forecast_model in summary_df['run_id']:\n",
        "    forecast_model = 'ForecastTCN'\n",
        "    \n",
        "best_dnn_run_id = summary_df['run_id'][forecast_model]\n",
        "best_dnn_run = Run(experiment, best_dnn_run_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_dnn_run.parent\n",
        "RunDetails(best_dnn_run.parent).show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_dnn_run\n",
        "RunDetails(best_dnn_run).show() "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "## Evaluate on Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "hideCode": false,
        "hidePrompt": false
      },
      "outputs": [],
      "source": [
        "We now use the best fitted model from the AutoML Run to make forecasts for the test set.  \n",
        "\n",
        "We always score on the original dataset whose schema matches the training set schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "test_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'beer-dataset/tabular/test.csv')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preview the first 3 rows of the dataset\n",
        "test_dataset.take(25).to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_target = ws.compute_targets['cpu-cluster']\n",
        "test_experiment = Experiment(ws, experiment_name + \"_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "script_folder = os.path.join(os.getcwd(), 'inference')\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "shutil.copy2('infer.py', script_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper import run_inference\n",
        "\n",
        "test_run = run_inference(test_experiment, compute_target, script_folder, best_dnn_run, test_dataset, valid_dataset, max_horizon,\n",
        "                 target_column_name, time_column_name, freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outpath = test_run._get_outputs_datapath()\n",
        "print(outpath.datastore_name)\n",
        "print(outpath.path_on_datastore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir(outpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper import run_multiple_inferences\n",
        "\n",
        "summary_df = run_multiple_inferences(summary_df, experiment, test_experiment, compute_target, script_folder, test_dataset, \n",
        "                  valid_dataset, max_horizon, target_column_name, time_column_name, freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for run_name, run_summary in summary_df.iterrows():\n",
        "    print(run_name)\n",
        "    print(run_summary)\n",
        "    run_id = run_summary.run_id\n",
        "    test_run_id = run_summary.test_run_id\n",
        "    test_run = Run(test_experiment, test_run_id)\n",
        "    test_run.wait_for_completion()\n",
        "    test_score = test_run.get_metrics()[run_summary.primary_metric]\n",
        "    summary_df.loc[summary_df.run_id == run_id, 'Test Score'] = test_score\n",
        "    print(\"Test Score: \", test_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "omkarm"
      }
    ],
    "hide_code_all_hidden": false,
    "kernelspec": {
      "display_name": "Python (py36_cloudML)",
      "language": "python",
      "name": "py36_cloudml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}